{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Data Collection & Processing\n",
    "## Weather Emergency Prediction -  Region\n",
    "\n",
    "This notebook handles:\n",
    "- Data loading from Excel/CSV files\n",
    "- Data preprocessing and cleaning\n",
    "- Feature engineering\n",
    "- Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# https://l4o2un2sj0p.sg.larksuite.com/wiki/VdF6wcDKAiV4Omkh2XVlOtzvgEh?from=from_copylink\n",
    "\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn plotly openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation/Loading\n",
    "\n",
    "### Option 1: Upload your own Excel/CSV files\n",
    "### Option 2: Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "ROSTOV_COORDS = {'lat': 47.2357, 'lon': 39.7015}\n",
    "START_YEAR = 2015\n",
    "YEARS_OF_DATA = 30\n",
    "\n",
    "def generate_weather_data(start_year=2015, num_years=30):\n",
    "    \"\"\"Generate synthetic weather data for Rostov region.\"\"\"\n",
    "    print(f\"Generating {num_years} years of weather data...\")\n",
    "    \n",
    "    # Generate date range\n",
    "    start_date = datetime(start_year, 1, 1)\n",
    "    end_date = start_date + timedelta(days=365 * num_years)\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    n = len(dates)\n",
    "    day_of_year = dates.dayofyear\n",
    "    \n",
    "    # Temperature with seasonal pattern (Rostov climate)\n",
    "    temp_base = 10 + 15 * np.sin(2 * np.pi * day_of_year / 365)\n",
    "    temperature = temp_base + np.random.normal(0, 5, n)\n",
    "    \n",
    "    # Precipitation with seasonal variation\n",
    "    precip_prob = 0.3 + 0.2 * np.sin(2 * np.pi * day_of_year / 365 + np.pi/2)\n",
    "    precipitation = np.random.gamma(2, 5, n) * (np.random.random(n) < precip_prob)\n",
    "    \n",
    "    # Humidity\n",
    "    humidity = np.clip(\n",
    "        50 + 20 * np.sin(2 * np.pi * day_of_year / 365 + np.pi/2) + np.random.normal(0, 10, n),\n",
    "        0, 100\n",
    "    )\n",
    "    \n",
    "    # Wind speed\n",
    "    wind_speed = np.abs(np.random.gamma(3, 2, n))\n",
    "    \n",
    "    # Pressure\n",
    "    pressure = 1013 + np.random.normal(0, 10, n)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'latitude': ROSTOV_COORDS['lat'],\n",
    "        'longitude': ROSTOV_COORDS['lon'],\n",
    "        'temperature': temperature,\n",
    "        'precipitation': precipitation,\n",
    "        'humidity': humidity,\n",
    "        'wind_speed': wind_speed,\n",
    "        'pressure': pressure\n",
    "    })\n",
    "    \n",
    "    print(f\"✅ Generated {len(df)} days of weather data\")\n",
    "    return df\n",
    "\n",
    "# Generate weather data\n",
    "weather_df = generate_weather_data(START_YEAR, YEARS_OF_DATA)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emergency_data(weather_df):\n",
    "    \"\"\"Generate emergency events based on weather conditions.\"\"\"\n",
    "    print(\"Generating emergency events...\")\n",
    "    \n",
    "    emergencies = []\n",
    "    \n",
    "    for idx, row in weather_df.iterrows():\n",
    "        # Heatwave: temp > 35°C\n",
    "        if row['temperature'] > 35 and np.random.random() < 0.3:\n",
    "            emergencies.append({\n",
    "                'date': row['date'],\n",
    "                'type': 'heatwave',\n",
    "                'severity': min(10, (row['temperature'] - 35) / 2),\n",
    "                'latitude': row['latitude'],\n",
    "                'longitude': row['longitude']\n",
    "            })\n",
    "        \n",
    "        # Drought: low precipitation + low humidity\n",
    "        if row['precipitation'] < 1 and row['humidity'] < 30 and np.random.random() < 0.1:\n",
    "            emergencies.append({\n",
    "                'date': row['date'],\n",
    "                'type': 'drought',\n",
    "                'severity': np.random.uniform(3, 7),\n",
    "                'latitude': row['latitude'],\n",
    "                'longitude': row['longitude']\n",
    "            })\n",
    "        \n",
    "        # Flood: heavy precipitation\n",
    "        if row['precipitation'] > 50 and np.random.random() < 0.4:\n",
    "            emergencies.append({\n",
    "                'date': row['date'],\n",
    "                'type': 'flood',\n",
    "                'severity': min(10, row['precipitation'] / 10),\n",
    "                'latitude': row['latitude'],\n",
    "                'longitude': row['longitude']\n",
    "            })\n",
    "        \n",
    "        # Frost: very low temperature\n",
    "        if row['temperature'] < -20 and np.random.random() < 0.3:\n",
    "            emergencies.append({\n",
    "                'date': row['date'],\n",
    "                'type': 'frost',\n",
    "                'severity': min(10, abs(row['temperature'] + 20) / 2),\n",
    "                'latitude': row['latitude'],\n",
    "                'longitude': row['longitude']\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(emergencies)\n",
    "    print(f\"✅ Generated {len(df)} emergency events\")\n",
    "    return df\n",
    "\n",
    "# Generate emergency data\n",
    "emergency_df = generate_emergency_data(weather_df)\n",
    "emergency_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Your Own Data (Alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to upload your own files\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# # Load weather data\n",
    "# weather_file = list(uploaded.keys())[0]\n",
    "# if weather_file.endswith('.csv'):\n",
    "#     weather_df = pd.read_csv(weather_file)\n",
    "# else:\n",
    "#     weather_df = pd.read_excel(weather_file)\n",
    "# weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "\n",
    "# # Load emergency data\n",
    "# emergency_file = list(uploaded.keys())[1]\n",
    "# if emergency_file.endswith('.csv'):\n",
    "#     emergency_df = pd.read_csv(emergency_file)\n",
    "# else:\n",
    "#     emergency_df = pd.read_excel(emergency_file)\n",
    "# emergency_df['date'] = pd.to_datetime(emergency_df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=\" * 50)\n",
    "print(\"WEATHER DATA STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(weather_df.describe())\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"EMERGENCY DATA STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "print(emergency_df['type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temperature trends\n",
    "fig = go.Figure()\n",
    "\n",
    "# Monthly aggregation\n",
    "monthly_temp = weather_df.groupby(weather_df['date'].dt.to_period('M')).agg({\n",
    "    'temperature': ['mean', 'min', 'max']\n",
    "}).reset_index()\n",
    "monthly_temp.columns = ['date', 'mean', 'min', 'max']\n",
    "monthly_temp['date'] = monthly_temp['date'].dt.to_timestamp()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=monthly_temp['date'], y=monthly_temp['mean'],\n",
    "                         name='Avg Temperature', line=dict(color='orange')))\n",
    "fig.add_trace(go.Scatter(x=monthly_temp['date'], y=monthly_temp['max'],\n",
    "                         name='Max Temperature', line=dict(color='red', dash='dot')))\n",
    "fig.add_trace(go.Scatter(x=monthly_temp['date'], y=monthly_temp['min'],\n",
    "                         name='Min Temperature', line=dict(color='blue', dash='dot')))\n",
    "\n",
    "fig.update_layout(title='Temperature Trends - Rostov-on-Don',\n",
    "                  xaxis_title='Date', yaxis_title='Temperature (°C)',\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize emergency distribution\n",
    "fig = px.pie(emergency_df, names='type', title='Emergency Types Distribution',\n",
    "             hole=0.3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, columns, n_std=3.0):\n",
    "    \"\"\"Remove outliers using z-score method.\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in df_clean.columns:\n",
    "            mean = df_clean[col].mean()\n",
    "            std = df_clean[col].std()\n",
    "            mask = np.abs(df_clean[col] - mean) <= n_std * std\n",
    "            df_clean = df_clean[mask]\n",
    "    \n",
    "    print(f\"Removed {len(df) - len(df_clean)} outlier rows\")\n",
    "    return df_clean\n",
    "\n",
    "# Remove outliers\n",
    "weather_clean = remove_outliers(weather_df, ['temperature', 'precipitation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_features(df):\n",
    "    \"\"\"Create time-based features.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    df['season'] = (df['month'] % 12 // 3 + 1)\n",
    "    \n",
    "    # Cyclical encoding\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "    \n",
    "    print(\"✅ Time features created\")\n",
    "    return df\n",
    "\n",
    "weather_clean = create_time_features(weather_clean)\n",
    "weather_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rolling_features(df, windows=[7, 14, 30]):\n",
    "    \"\"\"Create rolling window statistics.\"\"\"\n",
    "    df = df.copy().sort_values('date')\n",
    "    \n",
    "    features = ['temperature', 'precipitation', 'humidity', 'wind_speed', 'pressure']\n",
    "    \n",
    "    for feature in features:\n",
    "        if feature in df.columns:\n",
    "            for window in windows:\n",
    "                df[f'{feature}_rolling_mean_{window}d'] = \\\n",
    "                    df[feature].rolling(window=window, min_periods=1).mean()\n",
    "                df[f'{feature}_rolling_std_{window}d'] = \\\n",
    "                    df[feature].rolling(window=window, min_periods=1).std()\n",
    "                df[f'{feature}_rolling_min_{window}d'] = \\\n",
    "                    df[feature].rolling(window=window, min_periods=1).min()\n",
    "                df[f'{feature}_rolling_max_{window}d'] = \\\n",
    "                    df[feature].rolling(window=window, min_periods=1).max()\n",
    "    \n",
    "    print(f\"✅ Rolling features created for windows: {windows}\")\n",
    "    return df\n",
    "\n",
    "weather_clean = create_rolling_features(weather_clean, windows=[7, 14])\n",
    "print(f\"Total features: {len(weather_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features(df, lags=[1, 3, 7]):\n",
    "    \"\"\"Create lagged features.\"\"\"\n",
    "    df = df.copy().sort_values('date')\n",
    "    \n",
    "    features = ['temperature', 'precipitation', 'humidity']\n",
    "    \n",
    "    for feature in features:\n",
    "        if feature in df.columns:\n",
    "            for lag in lags:\n",
    "                df[f'{feature}_lag_{lag}d'] = df[feature].shift(lag)\n",
    "    \n",
    "    print(f\"✅ Lag features created for lags: {lags}\")\n",
    "    return df\n",
    "\n",
    "weather_clean = create_lag_features(weather_clean, lags=[1, 3, 7])\n",
    "print(f\"Total features: {len(weather_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Merge Weather and Emergency Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_weather_emergency(weather_df, emergency_df, window_days=3):\n",
    "    \"\"\"Merge weather and emergency data.\"\"\"\n",
    "    df = weather_df.copy()\n",
    "    df['has_emergency'] = 0\n",
    "    df['emergency_type'] = 'none'\n",
    "    df['emergency_severity'] = 0.0\n",
    "    \n",
    "    if len(emergency_df) > 0:\n",
    "        for _, emg in emergency_df.iterrows():\n",
    "            emg_date = pd.to_datetime(emg['date'])\n",
    "            mask = (\n",
    "                (df['date'] >= emg_date - timedelta(days=window_days)) &\n",
    "                (df['date'] <= emg_date)\n",
    "            )\n",
    "            df.loc[mask, 'has_emergency'] = 1\n",
    "            df.loc[mask, 'emergency_type'] = emg['type']\n",
    "            df.loc[mask, 'emergency_severity'] = emg['severity']\n",
    "    \n",
    "    print(f\"✅ Merged data: {df['has_emergency'].sum()} emergency days out of {len(df)} total days\")\n",
    "    return df\n",
    "\n",
    "# Merge data\n",
    "merged_df = merge_weather_emergency(weather_clean, emergency_df, window_days=3)\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV for use in Part B\n",
    "weather_clean.to_csv('weather_rostov_processed.csv', index=False)\n",
    "emergency_df.to_csv('emergencies_rostov.csv', index=False)\n",
    "merged_df.to_csv('merged_data_rostov.csv', index=False)\n",
    "\n",
    "print(\"✅ Data saved successfully!\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"- weather_rostov_processed.csv\")\n",
    "print(\"- emergencies_rostov.csv\")\n",
    "print(\"- merged_data_rostov.csv\")\n",
    "\n",
    "# Download files (uncomment if needed)\n",
    "# from google.colab import files\n",
    "# files.download('weather_rostov_processed.csv')\n",
    "# files.download('emergencies_rostov.csv')\n",
    "# files.download('merged_data_rostov.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✅ **Completed:**\n",
    "- Generated/Loaded 30 years of weather data for Rostov\n",
    "- Generated emergency events based on climatic criteria\n",
    "- Created time-based features (month, season, cyclical encodings)\n",
    "- Created rolling statistics (7-day, 14-day windows)\n",
    "- Created lag features (1, 3, 7 days)\n",
    "- Merged weather and emergency data\n",
    "- Saved processed data\n",
    "\n",
    "**Next:** Continue to Part B - Model Development\n",
    "\n",
    "\n",
    "$path = \"$env:USERPROFILE\\.claude\\settings.json\"\n",
    "mkdir \"$env:USERPROFILE\\.claude\" -Force\n",
    "@'\n",
    "{\n",
    "  \"env\": {\n",
    "    \"ANTHROPIC_API_KEY\": \"sk-\",\n",
    "    \"ANTHROPIC_BASE_URL\": \"https://code.ppchat.vip\"\n",
    "  },\n",
    "  \"permissions\": {\n",
    "    \"allow\": [],\n",
    "    \"deny\": []\n",
    "  },\n",
    "  \"apiKeyHelper\": \"echo 'sk-'\"\n",
    "}\n",
    "'@ | Out-File -Encoding utf8 $path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
